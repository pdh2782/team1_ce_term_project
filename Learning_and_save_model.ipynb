{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGd_mOJvfLc9"
   },
   "outputs": [],
   "source": [
    "#기초 library 호출\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.layers.convolutional import Conv2D\n",
    "#from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "# Data를 확인하는 부분\n",
    "filname = 'fer2013.csv' #저장한 학습데이터 이름\n",
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "names=['emotion','pixels','usage']\n",
    "df=pd.read_csv('fer2013.csv',names=names, na_filter=False)\n",
    "im=df['pixels']\n",
    "df.head(10)\n",
    "\n",
    "def getData(filname):\n",
    "    # images are 48x48\n",
    "    # N = 35887\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(filname):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0]))\n",
    "            X.append([int(p) for p in row[1].split()])\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y) #normalize하는 부분으로서 0과 1사이의 값으로 설정\n",
    "    return X, Y\n",
    "\n",
    "X, Y = getData(filname)\n",
    "num_class = len(set(Y))\n",
    "print(num_class) #분류하고 싶은 Class의 종류가 7가지임을 확인한다.\n",
    "\n",
    "# keras with tensorflow backend\n",
    "N, D = X.shape\n",
    "X = X.reshape(N, 48, 48, 1) # Input data는 48 x 48 x 1 의 픽셀정보를 가지고 있음\n",
    "\n",
    "#학습 데이터에서 몇 개를 training으로 할지 / 몇 개를 Test데이터로 할지 결정하는 구간\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
    "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)\n",
    "\n",
    "#layer를 쌓는 과정으로 직접 수정해보았음.\n",
    "def my_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    #model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same')) \n",
    "    #model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), input_shape=input_shape,activation='relu', padding='same')) \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    #model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n",
    "    #model.summary()\n",
    "    \n",
    "    return model\n",
    "model=my_model()\n",
    "model.summary()\n",
    "\n",
    "#실직적으로 학습하는 부분(수정전에는 약 60%의 정확도를 보여줌)\n",
    "path_model='model_filter.h5' # save model at this location after each epoch\n",
    "K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
    "model=my_model() # create the model\n",
    "K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n",
    "# fit the model\n",
    "h=model.fit(x=X_train,     \n",
    "            y=y_train, \n",
    "            batch_size=64, \n",
    "            epochs=20, \n",
    "            verbose=1, \n",
    "            validation_data=(X_test,y_test),\n",
    "            shuffle=True,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint(filepath=path_model),\n",
    "            ]\n",
    "            )\n",
    "\n",
    "objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "y_pos = np.arange(len(objects))\n",
    "print(y_pos)\n",
    "\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n",
    "    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "from keras.models import load_model\n",
    "cnn_model_dropout.save('cnn_model_dropout.h5') # 모델명.save('경로,파일명.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Learning_and_save_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
